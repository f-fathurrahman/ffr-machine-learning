%\documentclass[a4paper,11pt]{article} % print setting
\documentclass[a4paper,12pt]{article} % screen setting

\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=1.5cm,bmargin=1.5cm,lmargin=1.5cm,rmargin=1.5cm}

\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}

\usepackage{cmbright}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{fontspec}
\setmonofont{DejaVu Sans Mono}

%\usepackage{sfmath}
%\usepackage{mathptmx}
%\usepackage{mathpazo}

\usepackage{hyperref}
\usepackage{url}
\usepackage{xcolor}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}
\usepackage{float}

\usepackage{minted}

\newminted{julia}{breaklines,fontsize=\footnotesize}
\newminted{python}{breaklines,fontsize=\footnotesize}

\newminted{bash}{breaklines,fontsize=\footnotesize}
\newminted{text}{breaklines,fontsize=\footnotesize}

\newcommand{\txtinline}[1]{\mintinline[breaklines,fontsize=\footnotesize]{text}{#1}}
\newcommand{\jlinline}[1]{\mintinline[breaklines,fontsize=\footnotesize]{julia}{#1}}
\newcommand{\pyinline}[1]{\mintinline[breaklines,fontsize=\footnotesize]{python}{#1}}

\newmintedfile[juliafile]{julia}{breaklines,fontsize=\footnotesize}
\newmintedfile[pythonfile]{python}{breaklines,fontsize=\footnotesize}

\definecolor{mintedbg}{rgb}{0.90,0.90,0.90}
\usepackage{mdframed}

\BeforeBeginEnvironment{minted}{\begin{mdframed}[backgroundcolor=mintedbg]}
\AfterEndEnvironment{minted}{\end{mdframed}}

\usepackage{setspace}

\onehalfspacing

\usepackage{appendix}


\newcommand{\highlighteq}[1]{\colorbox{blue!25}{$\displaystyle#1$}}
\newcommand{\highlight}[1]{\colorbox{red!25}{#1}}



\begin{document}


\title{Linear Modeling - Least Square Approach \\
TF4xxx}
\author{Fadjar Fathurrahman}
\date{}
\maketitle

Diberikan pasangan data $(x,t)$ di mana $x$ adalah input dan $t$
adalah target, model linear dengan parameter $(w_0, w_1)$ dapat
dinyatakan sebagai:

\begin{equation}
\highlighteq{
t = f(x; w_0, w_1) = w_0 + w_1 x
}
\label{eq:model_linear_01}
\end{equation}

Untuk memilih model dengan parameter \((w_0, w_1)\) yang paling baik,
kita perlu mengkuantifikasi seberapa baik model tersebut. Salah satu ukuran
yang sering digunakan untuk hal ini adalah dengan menghitung kuadrat beda antara
target dan prediksi model. Untuk data ke-$n$ dapat dituliskan:
$$
\mathcal{L}_n = \left( t_n - f(x_n; w_0, w_1) \right)^2
$$
%
Dengan menjumlahkan $\mathcal{L}_{n}$ untuk semua data kita peroleh:
\begin{equation}
\mathcal{L} = \frac{1}{N} \sum_{n=1}^{N} \mathcal{L}_n
\label{eq:loss_function_01}
\end{equation}
Kuantitas ini akan kita sebut sebagai \highlight{loss function}.
Kita ingin kuantitas ini bernilai minimum.


Minimisasi loss function

Untuk mencari parameter $(w_{0},w_{1})$ yang memberikan loss function yang minimum
kita harus melakukan proses optimisasi (minimisasi). Pada umumnya kita dapat menggunakan
metode numerik seperti gradient descent.

$$
\arg\min_{w_{0},w_{1}} \frac{1}{N} \sum_{n=1}^{N} \mathcal{L}_{n}
$$

Untuk kasus loss function pada Pers. \eqref{eq:loss_function_01}, kita dapat mencari
minimumnya secara analitik: yaitu mencari nilai ekstrim dengan menyamakan turun pertama
dari loss function terhadap parameter model menjadi nol.

Untuk keperlua ini kita akan menuliskan loss function sebagai berikut:
\begin{align*}
\mathcal{L} & = \frac{1}{N} \sum_{n=1}^{N} \left( t_n - (w_0 + w_1 x_{n}) \right)^2 \\
& = \frac{1}{N} \sum_{n=1}^{N} \left( w_1^2 x_n^2 + 2w_{1}x_{n}(w_0 - t_n) + w_0^2 - 2w_0 t_n + t_n^2 \right)
\end{align*}


Hitung turunan pertama terhadap $w_0$ dan $w_1$, kemudian samakan dengan nol.

$$
\frac{\partial\mathcal{L}}{\partial w_1} = 2w_1 \frac{1}{N} \left( \sum_{n=1}^{N} x_n^2 \right) +
\frac{2}{N} \left( \sum_{n=1}^{N} x_{n} (w_0 - t_n) \right)
$$

$$
\frac{\partial \mathcal{L}}{\partial w_0} = 2w_0 + 2w_1 \frac{1}{N} \left( \sum_{n=1}^{N} x_n \right) -
\frac{2}{N} \left( \sum_{n=1}^{N} t_n \right)
$$

Sehingga diperoleh:
\begin{align}
w_{1} & = \frac{\overline{xt} - \overline{x}\overline{t}}{\overline{x^2} - \overline{x}^2} \\
w_{0} & = \overline{t} - w_{1} \overline{x}
\end{align}
di mana tanda overline menyatakan nilai rata-rata.


Tugas

Implementasikan program Python untuk menghitung $w_{0}$ dan $w_{1}$ untuk beberapa
dataset sederhana dan/atau dataset yang Anda buat sendiri.

Untuk menghitung rata-rata Anda dapat menggunakan metode \pyinline{np.mean}

Menggunakan notasi matriks dan vektor

Kita dapat menggunakan notasi matriks dan vektor untuk model linear.

Dengan mendefinisikan input dan parameter model sebagai vektor:
$$
\mathbf{x}_{n} = \begin{bmatrix}
1 \\
x_{n}
\end{bmatrix}
,\,\,\,%
\mathbf{w} = \begin{bmatrix}
w_{0} \\
w_{1}
\end{bmatrix}
$$
kita dapat menuliskan model linear sebagai pada Pers. \eqref{eq:model_linear_01}
sebagai:
\begin{equation}
f(x_n; w_0, w_1) = \mathbf{w}^{\mathsf{T}} \mathbf{x}_{n}
\label{eq:model_linear_02}
\end{equation}
%
dan loss function pada Pers. \eqref{eq:loss_function_01} menjadi
\begin{equation}
\mathcal{L} = \frac{1}{N} \sum_{n=1}^{N} \left( t_{n} - \mathbf{w}^{\mathsf{T}}
\mathbf{x}_{n} \right)^2
\label{eq:loss_function_02}
\end{equation}


Notasi matriks dan vektor

Kita dapat menyusun input vektor dalam suatu matriks:
$$
\mathbf{X} = \begin{bmatrix}
\mathbf{x}^{\mathsf{T}}_{1} \\
\mathbf{x}^{\mathsf{T}}_{2} \\
\vdots \\
\mathbf{x}^{\mathsf{T}}_{N}
\end{bmatrix} =
\begin{bmatrix}
1 & x_{1} \\
1 & x_{2} \\
\vdots & \vdots \\
1 & x_{N} \\
\end{bmatrix}
$$
%
Kemudian dengan mendefinisikan vektor target sebagai:
$$
\mathbf{t} = \begin{bmatrix}
t_1 \\
t_2 \\
\vdots \\
t_N
\end{bmatrix}
$$
%
Loss function dapat ditulis dengan lebih kompak:
$$
\mathcal{L} = \frac{1}{N} \left( \mathbf{t} - \mathbf{Xw} \right)^{\mathsf{T}}
\left( \mathbf{t} - \mathbf{Xw} \right)
$$

Minimisasi loss function

Untuk mencari nilai $\mathbf{w}$ yang optimal kita dapat melakukan prosedur
seperti sebelumnya, yaitu mencari solusi dari $\dfrac{\partial \mathcal{L}}{\partial \mathbf{w}} = 0$

\begin{align}
\mathcal{L} & = \frac{1}{N} \left(
\mathbf{t}^{\mathsf{T}} \mathbf{t} +
\left(\mathbf{Xw}\right)^{\mathsf{T}} \mathbf{Xw} -
\mathbf{t}\mathbf{Xw} -
\left(\mathbf{Xw}\right)^{\mathsf{T}} \mathbf{t}
\right) \\
& = \frac{1}{N} \left(
\mathbf{w}^{\mathsf{T}} \mathbf{X}^{\mathsf{T}} \mathbf{X} \mathbf{w} -
2 \mathbf{w}^{\mathsf{T}} \mathbf{X}^{\mathsf{T}}\mathbf{t} +
\mathbf{t}^{\mathsf{T}} \mathbf{t}
\right)
\end{align}

Nilai ekstrim dapat dicari dari:
$$
\frac{\partial \mathcal{L}}{\partial \mathbf{w}} =
\frac{2}{N} \left( \mathbf{X}^{\mathsf{T}} \mathbf{Xw} - \mathbf{X}^{\mathsf{T}}\mathbf{t} \right) = 0
$$

Sehingga diperoleh:
\begin{equation}
\mathbf{X}^{\mathsf{T}} \mathbf{Xw} = \mathbf{X}^{\mathsf{T}} \mathbf{t}
\end{equation}
atau:
\begin{equation}
\highlighteq{
\mathbf{w} = \left(\mathbf{X}^{\mathsf{T}}\mathbf{X} \right)^{-1} \mathbf{X}^{\mathsf{T}} \mathbf{t}
}
\label{eq:w_vektor}
\end{equation}


Tugas

Implementasikan program Python pada dataset yang sama dengan tugas sebelumnya
namun menggunakan notasi matriks-vektor sesuai Pers. \ref{eq:w_vektor}

Generalisasi

Kita dapat melakukan generalisasi model linear menjadi lebih kompleks, namun
masih linear dalam parameter model, misalnya dengan fungsi kuadratik:
\begin{equation}
f(x; w_{0}, w_{1}, w_{2}) = w_{0} +w_{1}x + w_{2}x^{2}
\end{equation}

Ukuran vektor $\mathbf{w}$ akan bertambah dan juga matriks $\mathbf{X}$ menjadi:
$$
\mathbf{X} = \begin{bmatrix}
\mathbf{x}^{\mathsf{T}}_{1} \\
\mathbf{x}^{\mathsf{T}}_{2} \\
\vdots \\
\mathbf{x}^{\mathsf{T}}_{N}
\end{bmatrix} =
\begin{bmatrix}
1 & x_{1} & x_{1}^{2} \\
1 & x_{2} & x_{1}^{2} \\
\vdots & & \vdots \vdots \\
1 & x_{N} & x_{N}^{2} \\
\end{bmatrix}
$$


Tugas

Sama seperti sebelumnya namun gunakan polinomial dengan orde > 1.

Apa yang terjadi jika orde polinomial menjadi semakin besar?


Regularisasi Model Linear

Ukuran kompleksitas model:
\begin{equation}
\sum_{i} w_{i}^{2}\,\,\text{atau }\mathbf{w}^{\mathsf{T}}\mathbf{w}
\end{equation}

Sebagai ganti dari minimisasi fungsi loss, kita dapat meminimisasi fungsi loss yang
sudah teregularisasi $\mathcal{L}$ dengan menambahkan suku penalti untuk overcomplexity:
\begin{equation}
\mathcal{L}' = \mathcal{L} + \lambda \mathbf{w}^{\mathsf{T}} \mathbf{w}
\end{equation}
Parameter $\lambda$ mengontrol trade-off antar fitting data dan model yang terlalu
kompleks.

Regularisasi

\begin{equation}
\mathcal{L}' = \frac{1}{N} \mathbf{w}^{\mathsf{T}} \mathbf{X}^{\mathsf{T}} \mathbf{X} \mathbf{w}
- \frac{2}{N} \mathbf{w}^{\mathsf{T}} \mathbf{X}^{\mathsf{T}} \mathbf{t}
+ \frac{1}{N} \mathbf{t}^{\mathsf{T}} \mathbf{t}
+ \lambda \mathbf{w}^{\mathsf{T}} \mathbf{w}
\end{equation}

Turunan parsial:
\begin{equation}
\frac{\partial \mathcal{L}'}{\partial \mathbf{w}} =
\frac{2}{N} \mathbf{X}^{\mathsf{T}} \mathbf{X} \mathbf{w}
- \frac{2}{N} \mathbf{X}^{\mathsf{T}} \mathbf{t} + 2\lambda\mathbf{w}
\end{equation}

Set menjadi nol untuk mendapatkan nilai ekstrim:
\begin{equation}
( \mathbf{X}^{\mathsf{T}} \mathbf{X} + N \lambda \mathbf{I} ) \mathbf{w} = \mathbf{X}^{\mathsf{T}} \mathbf{t}
\end{equation}

Sehingga diperoleh:
\begin{equation}
\hat{\mathbf{w}} =
( \mathbf{X}^{\mathsf{T}} \mathbf{X} + N \lambda \mathbf{I} )^{-1}
\mathbf{X}^{\mathsf{T}} \mathbf{t}
\end{equation}



\bibliographystyle{unsrt}
\bibliography{BIBLIO}

\end{document}
